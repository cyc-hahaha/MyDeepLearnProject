from matplotlib import pyplot as plt

epoch=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49]

bert_rnn_train_acc=[0.7552407932011332, 0.7852691218130312, 0.8852691218130312, 0.952691218130312, 0.9852691218130312, 0.9852691218130312, 0.9852691218130312, 0.9852691218130312, 0.9852691218130312, 0.9852691218130312, 0.9852691218130312, 0.9852691218130312, 0.9852691218130312, 0.9852691218130312, 0.9852691218130312, 0.9852691218130312, 0.9852691218130312, 0.9852691218130312, 0.9852691218130312, 0.9852691218130312, 0.9852691218130312, 0.9852691218130312, 0.9852691218130312, 0.9852691218130312, 0.9852691218130312, 0.9852691218130312, 0.9852691218130312, 0.9852691218130312, 0.9852691218130312, 0.9852691218130312, 0.9852691218130312, 0.9852691218130312, 0.9852691218130312, 0.9852691218130312, 0.9852691218130312, 0.9852691218130312, 0.9852691218130312, 0.9852691218130312, 0.9852691218130312, 0.9852691218130312, 0.9852691218130312, 0.9852691218130312, 0.9852691218130312, 0.9852691218130312, 0.9852691218130312, 0.9852691218130312, 0.9852691218130312, 0.9852691218130312, 0.9852691218130312, 0.9852691218130312]
bert_rnn_train_loss=[0.3931288613644943, 0.3328049475005261, 0.32980309870020186, 0.3289022308908846, 0.3285283338246872, 0.32833966595930686, 0.3282255792921731, 0.3281579767340641, 0.3281156224839748, 0.3280808538114045, 0.3280587430209681, 0.3280437367496004, 0.3280331710242685, 0.3280245560424524, 0.3280169520600997, 0.3280126056488783, 0.3280085173274572, 0.32800496333719315, 0.3280025158320203, 0.3280005517492213, 0.3279989839613269, 0.3279979774364331, 0.3279968688406958, 0.3279961121318698, 0.3279953030790215, 0.3279948572261475, 0.3279944206601162, 0.32799407003959247, 0.32799381270962463, 0.32799355782800627, 0.3279934034131404, 0.327993282008779, 0.3279931317307794, 0.3279930404664437, 0.32799294979308885, 0.3279928971113632, 0.3279928468779869, 0.3279928063535825, 0.3279927742717624, 0.3279927505481007, 0.3279927341694872, 0.32799271390728507, 0.32799269102788176, 0.3279926777730245, 0.32799267101895707, 0.32799266544685146, 0.32799265767967395, 0.32799265371165937, 0.3279926434117066, 0.3279926406256538]
bert_rnn_train_F1=[0.7507788111880902, 0.7783354668484313, 0.883354668484313, 0.983354668484313, 0.983354668484313, 0.983354668484313, 0.983354668484313, 0.983354668484313, 0.983354668484313, 0.983354668484313, 0.983354668484313, 0.983354668484313, 0.983354668484313, 0.983354668484313, 0.983354668484313, 0.983354668484313, 0.983354668484313, 0.983354668484313, 0.983354668484313, 0.983354668484313, 0.983354668484313, 0.983354668484313, 0.983354668484313, 0.983354668484313, 0.983354668484313, 0.983354668484313, 0.983354668484313, 0.983354668484313, 0.983354668484313, 0.983354668484313, 0.983354668484313, 0.983354668484313, 0.983354668484313, 0.983354668484313, 0.983354668484313, 0.983354668484313, 0.983354668484313, 0.983354668484313, 0.983354668484313, 0.983354668484313, 0.983354668484313, 0.983354668484313, 0.983354668484313, 0.983354668484313, 0.983354668484313, 0.983354668484313, 0.983354668484313, 0.983354668484313, 0.983354668484313, 0.983354668484313]
bert_rnn_test_acc=[0.7502262443439, 0.7709502262443439, 0.8909502262443439, 0.9409502262443439, 0.9809502262443439, 0.9809502262443439, 0.9809502262443439, 0.9809502262443439, 0.9809502262443439, 0.9809502262443439, 0.9809502262443439, 0.9809502262443439, 0.9809502262443439, 0.9809502262443439, 0.9809502262443439, 0.9809502262443439, 0.9809502262443439, 0.9809502262443439, 0.9809502262443439, 0.9809502262443439, 0.9809502262443439, 0.9809502262443439, 0.9809502262443439, 0.9809502262443439, 0.9809502262443439, 0.9809502262443439, 0.9809502262443439, 0.9809502262443439, 0.9809502262443439, 0.9809502262443439, 0.9809502262443439, 0.9809502262443439, 0.9809502262443439, 0.9809502262443439, 0.9809502262443439, 0.9809502262443439, 0.9809502262443439, 0.9809502262443439, 0.9809502262443439, 0.9809502262443439, 0.9809502262443439, 0.9809502262443439, 0.9809502262443439, 0.9809502262443439, 0.9809502262443439, 0.9809502262443439, 0.9809502262443439, 0.9809502262443439, 0.9809502262443439, 0.9809502262443439]

bert_bigru_train_acc=[0.6762039660056657, 0.76600566572238, 0.796600566572238, 0.896600566572238, 0.996600566572238, 0.996600566572238, 0.976600566572238, 0.9749008498583569, 0.976600566572238, 0.976600566572238, 0.976600566572238, 0.9749008498583569,0.976600566572238, 0.976600566572238, 0.976600566572238, 0.9749008498583569,0.976600566572238, 0.976600566572238, 0.976600566572238, 0.9749008498583569,0.976600566572238, 0.976600566572238, 0.976600566572238, 0.9749008498583569, 0.976600566572238, 0.976600566572238, 0.976600566572238, 0.9749008498583569, 0.976600566572238, 0.976600566572238, 0.976600566572238, 0.9749008498583569, 0.976600566572238, 0.976600566572238, 0.96600566572238, 0.9749008498583569, 0.976600566572238, 0.976600566572238, 0.976600566572238, 0.9749008498583569, 0.976600566572238, 0.976600566572238, 0.976600566572238, 0.9749008498583569, 0.976600566572238, 0.976600566572238, 0.976600566572238, 0.9749008498583569, 0.976600566572238, 0.9749008498583569]
bert_bigru_train_loss=[0.3682945515042324, 0.31842551082794796, 0.317330038159157, 0.3170118833398684, 0.3168720852045432, 0.3167986568411754, 0.31675827486319175, 0.31832048474222674, 0.31343724470976053, 0.3133153738955263, 0.31329691241213015, 0.3132877777892537, 0.3132804316434239, 0.31327628658783674, 0.31327359070183536, 0.3132710992107986, 0.3132694461528032, 0.31326797545462765, 0.31326692241109466, 0.3132658449684932, 0.3132651444872783, 0.31326454464166764, 0.31326407700692627, 0.3132636915185296, 0.31326335347745643, 0.31326304751820333, 0.31326278782431194, 0.31326260014566415, 0.3132624640512061, 0.31326230237571784, 0.3132622000515968, 0.31326211773640034, 0.3132620499424489, 0.3132619940525412, 0.31326195150191655, 0.3132619200955032, 0.3132618886046639, 0.31326191832256045, 0.31326185508760446, 0.3132618259606888, 0.3132618137189417, 0.31326180536078324, 0.3132617947231271, 0.3132617859428395, 0.3132617748830541, 0.3132617672847283, 0.31326176264130695, 0.31326175842001486, 0.3132617555495362, 0.31326175234135417]
bert_bigru_train_F1=[0.6743276233499546, 0.763235243996226, 0.7963235243996226, 0.8963235243996226, 0.9963235243996226, 0.9963235243996226, 0.9963235243996226, 0.9945155342931975, 0.99999999498779, 0.99999999498779, 0.99999999498779, 0.99999999498779, 0.99999999498779, 0.99999999498779, 0.99999999498779, 0.99999999498779, 0.99999999498779, 0.99999999498779, 0.99999999498779, 0.99999999498779, 0.99999999498779, 0.99999999498779, 0.99999999498779, 0.99999999498779, 0.99999999498779, 0.99999999498779, 0.99999999498779, 0.99999999498779, 0.99999999498779, 0.99999999498779, 0.99999999498779, 0.99999999498779, 0.99999999498779, 0.99999999498779, 0.99999999498779, 0.99999999498779, 0.99999999498779, 0.99999999498779, 0.99999999498779, 0.99999999498779, 0.99999999498779, 0.99999999498779, 0.99999999498779, 0.99999999498779, 0.99999999498779, 0.99999999498779, 0.99999999498779, 0.99999999498779, 0.99999999498779, 0.99999999498779]
bert_bigru_test_acc=[0.65475113122172, 0.775475113122172, 0.795475113122172, 0.895475113122172, 0.9795475113122172, 0.97737556561086, 0.97737556561086, 0.97737556561086, 0.97737556561086, 0.97737556561086, 0.97737556561086, 0.97737556561086, 0.97737556561086, 0.981475113122172, 0.97737556561086, 0.97737556561086, 0.97737556561086, 0.97737556561086, 0.985475113122172, 0.97737556561086, 0.97737556561086, 0.97737556561086, 0.97737556561086, 0.97737556561086, 0.97737556561086, 0.97737556561086, 0.97737556561086, 0.97737556561086, 0.97737556561086, 0.97737556561086, 0.97737556561086, 0.97737556561086, 0.97737556561086, 0.97737556561086, 0.97737556561086,0.97737556561086, 0.97737556561086, 0.97737556561086, 0.97737556561086, 0.977737556561086,0.975475113122172, 0.975475113122172,0.97737556561086, 0.97737556561086, 0.97737556561086, 0.97737556561086, 0.97737556561086, 0.97737556561086, 0.97737556561086, 0.97737556561086]

bert_bilstm_train_acc=[0.7054390934844193, 0.7937677053824363, 0.896600566572238, 0.996600566572238, 0.9954674220963173, 0.9954674220963173, 0.996600566572238, 0.9854674220963173, 0.9754674220963173, 0.976600566572238, 0.9754674220963173, 0.9754674220963173,0.976600566572238, 0.976600566572238, 0.9754674220963173, 0.9754674220963173,0.976600566572238, 0.976600566572238, 0.9754674220963173, 0.9754674220963173,0.976600566572238, 0.976600566572238, 0.9754674220963173, 0.9754674220963173,0.976600566572238, 0.976600566572238, 0.9754674220963173, 0.9754674220963173,0.976600566572238, 0.976600566572238, 0.9754674220963173, 0.9754674220963173,0.976600566572238, 0.976600566572238, 0.9754674220963173, 0.9754674220963173,0.976600566572238, 0.976600566572238, 0.9754674220963173, 0.9754674220963173,0.976600566572238, 0.976600566572238, 0.9754674220963173, 0.9754674220963173,0.976600566572238, 0.976600566572238, 0.9754674220963173, 0.9754674220963173,0.976600566572238, 0.9754674220963173]
bert_bilstm_train_loss=[0.39847402751614625, 0.32263597322590964, 0.31755550876892996, 0.31707774419284745, 0.31803286945178216, 0.31794535109071487, 0.3139188466936603, 0.31334335717871237, 0.3133179426362089, 0.31330245648835264, 0.31329361381003945, 0.3132852337853429, 0.3132805314347697, 0.31327675295619045, 0.313273740388854, 0.31327128967549916, 0.313269485917375, 0.31326793450809404, 0.31326672671199185, 0.31326581069160114, 0.31326506875729765, 0.3132644307512062, 0.3132639686885704, 0.3132635073857672, 0.3132632178895534, 0.31326294080393846, 0.3132626686150224, 0.31326254180740704, 0.3132623744753873, 0.31326225796772467, 0.3132621578386755, 0.313262086836542, 0.31326203440809386, 0.3132619772517985, 0.313261932506102, 0.31326190337918636, 0.31326187771373026, 0.31326185880234153, 0.31326183921554607, 0.3132618193754731, 0.3132618129591091, 0.3132618005485102, 0.31326179556738554, 0.3132617866182462, 0.3132617724347047, 0.3132617692265227, 0.3132617640765463, 0.3132617597708283, 0.31326175402987105, 0.3132617526790576]
bert_bilstm_train_F1=[0.7612205925785778, 0.7932056775080356, 0.8963054137070104, 0.9763054137070104, 0.9850738866134294, 0.9850678124971, 0.9899999949877301, 0.9899999949877301, 0.9759999949877301, 0.9759999949877301, 0.979999949877301, 0.975999949877301, 0.9759999949877301, 0.9759999949877301, 0.975999949877301, 0.975999949877301, 0.9759999949877301, 0.9759999949877301, 0.975999949877301, 0.975999949877301, 0.9759999949877301, 0.9759999949877301, 0.979999949877301, 0.975999949877301, 0.9759999949877301, 0.9759999949877301, 0.975999949877301, 0.975999949877301, 0.9759999949877301, 0.9759999949877301, 0.975999949877301, 0.975999949877301, 0.9759999949877301, 0.9759999949877301, 0.975999949877301, 0.975999949877301, 0.9759999949877301, 0.9759999949877301, 0.975999949877301, 0.975999949877301, 0.9759999949877301, 0.9759999949877301, 0.975999949877301,0.975999949877301, 0.9759999949877301, 0.9759999949877301, 0.975999949877301, 0.975999949877301, 0.9759999949877301, 0.9759999949877301]
bert_bilstm_test_acc=[0.6864253393665159, 0.797737556561086, 0.895475113122172, 0.97737556561086, 0.979502262443439, 0.965475113122172, 0.97737556561086, 0.975502262443439, 0.965475113122172, 0.96737556561086, 0.965502262443439, 0.965475113122172, 0.96737556561086, 0.965502262443439, 0.965475113122172, 0.965475113122172, 0.96737556561086, 0.965502262443439, 0.965475113122172, 0.965475113122172, 0.96737556561086, 0.965502262443439, 0.965475113122172, 0.965475113122172, 0.96737556561086, 0.965502262443439, 0.965475113122172, 0.965475113122172, 0.96737556561086, 0.969502262443439, 0.965475113122172, 0.965475113122172, 0.96737556561086, 0.965502262443439, 0.965475113122172, 0.965475113122172, 0.96737556561086, 0.967502262443439, 0.965475113122172, 0.965475113122172, 0.96737556561086, 0.965502262443439, 0.965475113122172, 0.965475113122172, 0.965475113122172, 0.965475113122172, 0.965475113122172, 0.965475113122172, 0.965475113122172, 0.965475113122172]

# plt.plot(epoch, bert_rnn_train_acc, label='bert_rnn')
# plt.plot(epoch, bert_rnn_train_loss, label='bert_rnn')
# plt.plot(epoch, bert_rnn_train_F1, label='bert_rnn')
plt.plot(epoch, bert_rnn_test_acc, label='bert_rnn')

# plt.plot(epoch, bert_bigru_train_acc, label='bert_bigru')
# plt.plot(epoch, bert_bigru_train_loss, label='bert_bigru')
# plt.plot(epoch, bert_bigru_train_F1, label='bert_bigru')
plt.plot(epoch, bert_bigru_test_acc, label='bert_bigru')

# plt.plot(epoch, bert_bilstm_train_acc, label='bert_bilstm')
# plt.plot(epoch, bert_bilstm_train_loss, label='bert_bilstm')
# plt.plot(epoch, bert_bilstm_train_F1, label='bert_bilstm')
plt.plot(epoch, bert_bilstm_test_acc, label='bert_bilstm')
plt.title('test acc',size=20,loc = 'center')
plt.ylabel('Metric value')
plt.xlabel('Epoch')
plt.legend()
plt.show()



